{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias basicas\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import  R2Score, MeanAbsoluteError\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(c_in, c_out):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, 3, padding=1),\n",
    "        torch.nn.BatchNorm2d(c_out),\n",
    "        torch.nn.ReLU(inplace=True)\n",
    "    )\n",
    "def encoder(c_in, c_out):\n",
    "  return torch.nn.Sequential(\n",
    "        torch.nn.MaxPool2d(2),\n",
    "        conv3x3(c_in, c_out),\n",
    "        conv3x3(c_out, c_out),\n",
    "    )\n",
    "\n",
    "class decoder(torch.nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(decoder, self).__init__()\n",
    "        self.upsample = torch.nn.ConvTranspose2d(c_in, c_out, 2, stride=2)\n",
    "        self.conv1 = conv3x3(c_in, c_out)\n",
    "        self.conv2 = conv3x3(c_out, c_out)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upsample(x1)\n",
    "        diff_X = x2.size()[2] - x1.size()[2]\n",
    "        diff_Y = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diff_X, 0, diff_Y, 0))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes=1, in_ch=1, c = 16):\n",
    "        super().__init__()\n",
    "        self.encoder1 = torch.nn.Sequential(\n",
    "          conv3x3(in_ch, c),\n",
    "          conv3x3(c, c),\n",
    "        )\n",
    "        self.encoder2 = encoder(c, 2*c)\n",
    "        self.encoder3 = encoder(2*c, 4*c)\n",
    "        self.encoder4 = encoder(4*c, 8*c)\n",
    "        self.decoder1 = decoder(8*c,4*c)\n",
    "        self.decoder2 = decoder(4*c,2*c)\n",
    "        self.decoder3 = decoder(2*c,c)\n",
    "        self.out = torch.nn.Conv2d(c, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder1(x)\n",
    "        x2 = self.encoder2(x1)\n",
    "        x3 = self.encoder3(x2)\n",
    "        x = self.encoder4(x3)\n",
    "        x = self.decoder1(x, x3)\n",
    "        x = self.decoder2(x, x2)\n",
    "        x = self.decoder3(x, x1)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(c = 16)\n",
    "num_params = count_parameters(model)\n",
    "print(num_params)\n",
    "output = model(torch.randn((50,1,112,112)))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X, y):\n",
    "        N,W,H = X.shape\n",
    "        self.img=torch.tensor(X.reshape(N,1,W,H).astype(np.float32))\n",
    "        self.mask=torch.tensor(y.reshape(N,1,W,H).astype(np.float32))\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx],self.mask[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = np.load(\"your_images_data.npy\",allow_pickle=True)\n",
    "dataset_mask = np.load(\"your_masks_data.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,W,H = dataset_images.shape\n",
    "N_training = int(0.6*N)\n",
    "N_validation = int(0.2*N) + N_training\n",
    "dataset = {\n",
    "    'train': Dataset(dataset_images[:N_training], dataset_mask[:N_training]), \n",
    "    'valid': Dataset(dataset_images[N_training:N_validation], dataset_mask[N_training:N_validation]),\n",
    "    'test': Dataset(dataset_images[N_validation:], dataset_mask[N_validation:])\n",
    "}\n",
    "\n",
    "dataloader = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=50, shuffle=True, pin_memory=True),\n",
    "    'valid': DataLoader(dataset['valid'], batch_size=100, pin_memory=True),\n",
    "    'test': DataLoader(dataset['test'], batch_size=100, pin_memory=True)\n",
    "}\n",
    "\n",
    "\n",
    "len(dataset['train']), len(dataset['valid']), len(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(outputs, labels):\n",
    "    outputs, labels = torch.sigmoid(outputs) > 0.5, labels > 0.5\n",
    "    SMOOTH = 1e-6\n",
    "    ious = []\n",
    "    intersection = (outputs & labels).float().sum((1, 2))  \n",
    "    union = (outputs | labels).float().sum((1, 2))         \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  \n",
    "    ious.append(iou.mean().item())\n",
    "    return np.mean(ious) \n",
    "\n",
    "def dice_coeff(outputs, labels, smooth=1e-6):\n",
    "    outputs = (torch.sigmoid(outputs) > 0.5).float()\n",
    "    labels = (labels > 0.5).float()\n",
    "    intersection = (outputs * labels).sum((1, 2))\n",
    "    union = outputs.sum((1, 2)) + labels.sum((1, 2))\n",
    "    dice = (2 * intersection + smooth) / (union + smooth)\n",
    "    return dice.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.max_split_size_mb = 1024\n",
    "\n",
    "def fit(model, dataloader, epochs=100, lr=3e-4, sub_batch_size=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    model.to(device)\n",
    "    hist = {'loss': [], 'iou': [], 'dice': [], 'val_loss': [], 'val_iou': [], 'val_dice': []}\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        bar = tqdm(dataloader['train'])\n",
    "        train_loss, train_iou, train_dice = [], [], []\n",
    "        model.train()\n",
    "\n",
    "        for imgs, masks in bar:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            num_sub_batches = len(imgs) // sub_batch_size\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for j in range(num_sub_batches):\n",
    "                start = j * sub_batch_size\n",
    "                end = start + sub_batch_size\n",
    "                y_hat = model(imgs[start:end])\n",
    "                loss = criterion(y_hat, masks[start:end])\n",
    "                loss.backward()\n",
    "                ious = iou(y_hat, masks[start:end])\n",
    "                dices = dice_coeff(y_hat, masks[start:end])\n",
    "                train_loss.append(loss.item())\n",
    "                train_iou.append(ious)\n",
    "                train_dice.append(dices)\n",
    "\n",
    "            optimizer.step()\n",
    "            bar.set_description(f\"loss {np.mean(train_loss):.5f} iou {np.mean(train_iou):.5f} dice {np.mean(train_dice):.5f}\")\n",
    "\n",
    "        hist['loss'].append(np.mean(train_loss))\n",
    "        hist['iou'].append(np.mean(train_iou))\n",
    "        hist['dice'].append(np.mean(train_dice))\n",
    "        bar = tqdm(dataloader['valid'])\n",
    "        val_loss, val_iou, val_dice = [], [], []\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in bar:\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                y_hat = model(imgs)\n",
    "                loss = criterion(y_hat, masks)\n",
    "                ious = iou(y_hat, masks)\n",
    "                dices = dice_coeff(y_hat, masks)\n",
    "                val_loss.append(loss.item())\n",
    "                val_iou.append(ious)\n",
    "                val_dice.append(dices)\n",
    "\n",
    "        hist['val_loss'].append(np.mean(val_loss))\n",
    "        hist['val_iou'].append(np.mean(val_iou))\n",
    "        hist['val_dice'].append(np.mean(val_dice))\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} iou {np.mean(train_iou):.5f} dice {np.mean(train_dice):.5f} val_loss {np.mean(val_loss):.5f} val_iou {np.mean(val_iou):.5f} val_dice {np.mean(val_dice):.5f}\")\n",
    "\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(c=16)\n",
    "hist = fit(model, dataloader, epochs=9, sub_batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = tqdm(dataloader['test'])\n",
    "hist_test = {'test_loss': [], 'test_iou': [], 'test_dice': []}\n",
    "test_loss, test_iou, test_dice = [], [], []\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in bar:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        y_hat = model(imgs)\n",
    "        loss = criterion(y_hat, masks)\n",
    "        ious = iou(y_hat, masks)\n",
    "        dices = dice_coeff(y_hat, masks)\n",
    "        test_loss.append(loss.item())\n",
    "        test_iou.append(ious)\n",
    "        test_dice.append(dices)\n",
    "\n",
    "hist_test['test_loss'].append(np.mean(test_loss))\n",
    "hist_test['test_iou'].append(np.mean(test_iou))\n",
    "hist_test['test_dice'].append(np.mean(test_dice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EF ESTIMATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionHead(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super(RegressionHead, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, 1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class reduce_cnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(reduce_cnn, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 3)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3)\n",
    "        self.conv5 = torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3)\n",
    "        self.pool = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.normalize(F.relu(self.conv1(x))))\n",
    "        x = self.pool(F.normalize(F.relu(self.conv2(x))))\n",
    "        x = self.pool(F.normalize(F.relu(self.conv3(x))))\n",
    "        x = self.pool(F.normalize(F.relu(self.conv4(x))))\n",
    "        x = self.pool(F.normalize(F.relu(self.conv5(x))))\n",
    "        N,C,W,H = x.shape \n",
    "        return x.reshape(N,C*H*W)\n",
    "\n",
    "class UnetToRegressor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnetToRegressor, self).__init__()\n",
    "        self.unet = UNet()\n",
    "        #self.unet = torch.load('model_Unet.pt')\n",
    "        self.reduce = reduce_cnn()\n",
    "        self.regression_head = RegressionHead(768)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N,C,W,H = x.shape\n",
    "        x1, x2 = x[:,0,:,:].reshape(N,1,W,H), x[:,1,:,:].reshape(N,1,W,H)\n",
    "        x1, x2 = self.unet(x1), self.unet(x2)\n",
    "        x_diff = torch.abs(x1 - x2)\n",
    "        x1,x2,x_diff = self.reduce(x1), self.reduce(x2), self.reduce(x_diff)\n",
    "        x = torch.cat([x1.view(x1.size(0), -1), x2.view(x2.size(0), -1), x_diff.view(x_diff.size(0), -1)], dim=1)\n",
    "        x = self.regression_head(x)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetToRegressor()\n",
    "num_params = count_parameters(model)\n",
    "print(num_params)\n",
    "output = model(torch.randn((50,2,112,112)))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self,X, y):\n",
    "        self.img=torch.tensor(X.astype(np.float32))\n",
    "        self.y=torch.tensor(y.astype(np.float32))\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_img_ef = np.load(\"your_images_ef_data.npy\",allow_pickle=True)\n",
    "y_ef = np.load(\"your_ef_data.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,C,H,W = np.array(dataset_img_ef).shape\n",
    "N_training = int(0.6*N)\n",
    "N_validation = int(0.2*N) + N_training\n",
    "indices = np.random.permutation(len(dataset_img_ef))\n",
    "dataset_img_ef= dataset_img_ef[indices]\n",
    "y_ef= y_ef[indices]\n",
    "dataset2 = {\n",
    "    'train': Dataset2(np.array(dataset_img_ef[:N_training]), y_ef[:N_training]), \n",
    "    'valid': Dataset2(np.array(dataset_img_ef[N_training:N_validation]), y_ef[N_training:N_validation]),\n",
    "    'test': Dataset2(np.array(dataset_img_ef[N_validation:]), y_ef[N_validation:])\n",
    "}\n",
    "dataloader2 = {\n",
    "    'train': DataLoader(dataset2['train'], batch_size=50, shuffle=True, pin_memory=True),\n",
    "    'valid': DataLoader(dataset2['valid'], batch_size=100, pin_memory=True),\n",
    "    'test': DataLoader(dataset2['test'], batch_size=100, pin_memory=True)\n",
    "}\n",
    "print(len(dataset2['train']), len(dataset2['valid']), len(dataset2['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_metric = R2Score()\n",
    "mae_metric = MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def fit(model, dataloader, epochs=100, lr=3e-4, sub_batch_size=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    model.to(device)\n",
    "    best_r_squared = 0.75 \n",
    "    hist = {'loss': [], 'mae': [], 'val_loss': [], 'val_mae': [], 'val_r_squared': []}\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        bar = tqdm(dataloader['train'])\n",
    "        train_loss, train_mae = [], []\n",
    "        model.train()\n",
    "        for imgs, masks in bar:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            num_sub_batches = len(imgs) // sub_batch_size\n",
    "            optimizer.zero_grad()\n",
    "            for j in range(num_sub_batches):\n",
    "                start = j * sub_batch_size\n",
    "                end = start + sub_batch_size\n",
    "                y_hat = model(imgs[start:end])\n",
    "                loss = criterion(y_hat, masks[start:end])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                maes = mae_metric(y_hat.cpu().detach(), masks[start:end].cpu().detach())\n",
    "                train_loss.append(loss.item())\n",
    "                train_mae.append(maes)\n",
    "            bar.set_description(f\"loss {np.mean(train_loss):.5f} mae {np.mean(train_mae):.5f}\")\n",
    "        hist['loss'].append(np.mean(train_loss))\n",
    "        hist['mae'].append(np.mean(train_mae))\n",
    "\n",
    "        bar = tqdm(dataloader['valid'])\n",
    "        val_loss, val_mae, val_r_squared = [], [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in bar:\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                y_hat = model(imgs)\n",
    "                loss = criterion(y_hat, masks)\n",
    "                maes = mae_metric(y_hat.cpu().detach(), masks.cpu().detach())\n",
    "                r_squareds = r2_metric(y_hat.cpu().detach(), masks.cpu().detach())\n",
    "                val_loss.append(loss.item())\n",
    "                val_mae.append(maes)\n",
    "                val_r_squared.append(r_squareds)\n",
    "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f}  val_mae {np.mean(val_mae):.5f} val_r_squared {np.mean(val_r_squared):.5f}\")\n",
    "        hist['val_loss'].append(np.mean(val_loss))\n",
    "        hist['val_mae'].append(np.mean(val_mae))\n",
    "        hist['val_r_squared'].append(np.mean(val_r_squared))\n",
    "        mean_val_r_squared = np.mean(val_r_squared)\n",
    "        if mean_val_r_squared > best_r_squared:\n",
    "            torch.save(model, 'the_ef_estimator.pt')\n",
    "            best_r_squared = mean_val_r_squared\n",
    "            print(f\"Model saved with test_r_squared: {mean_val_r_squared}\")\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} mae {np.mean(train_mae):.5f} val_loss {np.mean(val_loss):.5f} val_mae {np.mean(val_mae):.5f} val_r_squared {np.mean(val_r_squared):.5f}\")\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetToRegressor()\n",
    "hist = fit(model, dataloader2, epochs=50, sub_batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('the_ef_estimator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = tqdm(dataloader['test'])\n",
    "hist_test = {'test_loss': [], 'test_mae': [], 'test_r_squared': []}\n",
    "test_loss, test_mae, test_r_squared = [], [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in bar:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        y_hat = model(imgs)\n",
    "        loss = criterion(y_hat, masks)\n",
    "        maes = mae_metric(y_hat.cpu().detach(), masks.cpu().detach())\n",
    "        r_squareds = r2_metric(y_hat.cpu().detach(), masks.cpu().detach())\n",
    "        test_loss.append(loss.item())\n",
    "        test_mae.append(maes)\n",
    "        test_r_squared.append(r_squareds)\n",
    "        \n",
    "hist_test['test_loss'].append(np.mean(test_loss))\n",
    "hist_test['test_mae'].append(np.mean(test_mae))\n",
    "hist_test['test_r_squared'].append(np.mean(test_r_squared))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
